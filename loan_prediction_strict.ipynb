{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ea8ad59",
   "metadata": {},
   "source": [
    "# Loan Prediction\n",
    "\n",
    "### Developed by:\n",
    "\n",
    "1. Tiago Pinheiro - 202205295\n",
    "2. Tiago Rocha    - 202005428\n",
    "3. Vasco Melo     - 202207564\n",
    "\n",
    "## 1. Data Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3213bf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "dataset = pd.read_csv('data/credit_risk_dataset.csv')\n",
    "\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "display(dataset.head())\n",
    "\n",
    "print(\"\\nDataset info:\")\n",
    "display(dataset.info())\n",
    "\n",
    "print(\"\\nDataset statistics:\")\n",
    "display(dataset.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e090d09c",
   "metadata": {},
   "source": [
    "## 2. Comprehensive Exploratory Data Analysis\n",
    "\n",
    "### 2.1 Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b1f531",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of rows: {dataset.shape[0]}\")\n",
    "print(f\"Number of columns: {dataset.shape[1]}\")\n",
    "\n",
    "duplicate_count = dataset.duplicated().sum()\n",
    "print(f\"\\nNumber of duplicate rows: {duplicate_count}\")\n",
    "\n",
    "print(\"\\nTarget variable (loan_status) distribution:\")\n",
    "loan_status_counts = dataset['loan_status'].value_counts()\n",
    "display(loan_status_counts)\n",
    "print(f\"Percentage of loan defaults: {loan_status_counts[1] / len(dataset) * 100:.2f}%\")\n",
    "\n",
    "print(\"\\nData types:\")\n",
    "display(dataset.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9829de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove id\n",
    "dataset.drop(columns=['id'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d068dc",
   "metadata": {},
   "source": [
    "### 2.2 Identify and Handle Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26cb36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Entries with person_age > 120:\")\n",
    "removed_age_entries = dataset[dataset['person_age'] > 120]\n",
    "display(removed_age_entries)\n",
    "\n",
    "print(\"\\nEntries with person_emp_length > person_age:\")\n",
    "removed_emp_length_entries = dataset[dataset['person_emp_length'] > dataset['person_age']]\n",
    "display(removed_emp_length_entries)\n",
    "\n",
    "all_removed_entries = pd.concat([removed_age_entries, removed_emp_length_entries]).drop_duplicates()\n",
    "print(\"\\nAll entries to be removed:\")\n",
    "display(all_removed_entries)\n",
    "print(f\"Total anomalous entries: {len(all_removed_entries)} ({len(all_removed_entries)/len(dataset)*100:.2f}% of dataset)\")\n",
    "\n",
    "dataset = dataset[dataset['person_age'] <= 120]\n",
    "dataset = dataset[dataset['person_emp_length'] <= dataset['person_age']]\n",
    "\n",
    "print(\"\\nDataset after removing invalid entries:\")\n",
    "display(dataset.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d258dc8",
   "metadata": {},
   "source": [
    "### 2.3 Missing Value Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c1b944",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = dataset.isnull().sum()\n",
    "\n",
    "print(\"Columns with missing values:\")\n",
    "missing_data = missing_data[missing_data > 0]\n",
    "if not missing_data.empty:\n",
    "    display(missing_data)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(missing_data.index, missing_data.values)\n",
    "    plt.title('Missing Values by Column')\n",
    "    plt.xlabel('Column')\n",
    "    plt.ylabel('Number of Missing Values')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    missing_percentage = (missing_data / len(dataset)) * 100\n",
    "    print(\"\\nPercentage of missing values:\")\n",
    "    display(missing_percentage)\n",
    "else:\n",
    "    print(\"No missing values found in the dataset.\")\n",
    "\n",
    "dataset = dataset.dropna()\n",
    "print(f\"\\nDataset shape after handling missing values: {dataset.shape}\")\n",
    "\n",
    "print(\"Checking for any remaining missing values:\")\n",
    "display(dataset.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0d8661",
   "metadata": {},
   "source": [
    "### 2.4 Detailed Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eb0143",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = dataset.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "numerical_features.remove('loan_status')  # Remove target variable\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, feature in enumerate(numerical_features, 1):\n",
    "    plt.subplot(3, 3, i)\n",
    "    sns.histplot(dataset[feature], kde=True)\n",
    "    plt.title(f'Distribution of {feature}')\n",
    "    plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "categorical_features = dataset.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, feature in enumerate(categorical_features, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    sns.countplot(x=feature, data=dataset)\n",
    "    plt.title(f'Distribution of {feature}')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, feature in enumerate(categorical_features, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    sns.countplot(x=feature, hue='loan_status', data=dataset)\n",
    "    plt.title(f'{feature} vs. Loan Status')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cf611e",
   "metadata": {},
   "source": [
    "### 2.5 Feature Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be64fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_numeric = dataset.copy()\n",
    "\n",
    "home_ownership_map = {\n",
    "    'MORTGAGE': 0,\n",
    "    'RENT': 1,\n",
    "    'OWN': 2,\n",
    "    'OTHER': 3\n",
    "}\n",
    "dataset_numeric['person_home_ownership'] = dataset_numeric['person_home_ownership'].map(home_ownership_map)\n",
    "\n",
    "loan_intent_map = {\n",
    "    'VENTURE': 0,\n",
    "    'EDUCATION': 1,\n",
    "    'DEBTCONSOLIDATION': 2,\n",
    "    'HOMEIMPROVEMENT': 3,\n",
    "    'MEDICAL': 4,\n",
    "    'PERSONAL': 5\n",
    "}\n",
    "dataset_numeric['loan_intent'] = dataset_numeric['loan_intent'].map(loan_intent_map)\n",
    "\n",
    "loan_grade_map = {\n",
    "    'A': 0,\n",
    "    'B': 1,\n",
    "    'C': 2,\n",
    "    'D': 3,\n",
    "    'E': 4,\n",
    "    'F': 5,\n",
    "    'G': 6\n",
    "}\n",
    "dataset_numeric['loan_grade'] = dataset_numeric['loan_grade'].map(loan_grade_map)\n",
    "\n",
    "cb_person_default_map = {\n",
    "    'Y': 1,\n",
    "    'N': 0\n",
    "}\n",
    "dataset_numeric['cb_person_default_on_file'] = dataset_numeric['cb_person_default_on_file'].map(cb_person_default_map)\n",
    "\n",
    "correlation_matrix = dataset_numeric.corr()\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "plt.title('Correlation Matrix of Features')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "target_correlations = correlation_matrix['loan_status'].drop('loan_status')\n",
    "print(\"Correlations with target variable (loan_status):\")\n",
    "display(target_correlations.sort_values(ascending=False))\n",
    "\n",
    "top_correlated = target_correlations.abs().sort_values(ascending=False)[:5]\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=top_correlated.index, y=top_correlated.values)\n",
    "plt.title('Top 5 Features Correlated with Loan Status')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52619e78",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering and Preprocessing\n",
    "\n",
    "### 3.1 Feature Encoding and Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fbb4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_encoded = dataset.copy()\n",
    "\n",
    "dataset_encoded['person_home_ownership'] = dataset_encoded['person_home_ownership'].map(home_ownership_map)\n",
    "dataset_encoded['loan_intent'] = dataset_encoded['loan_intent'].map(loan_intent_map)\n",
    "dataset_encoded['loan_grade'] = dataset_encoded['loan_grade'].map(loan_grade_map)\n",
    "dataset_encoded['cb_person_default_on_file'] = dataset_encoded['cb_person_default_on_file'].map(cb_person_default_map)\n",
    "\n",
    "print(\"Data types after encoding:\")\n",
    "display(dataset_encoded.dtypes)\n",
    "\n",
    "non_numeric = dataset_encoded.select_dtypes(include=['object']).columns.tolist()\n",
    "if non_numeric:\n",
    "    print(f\"Remaining non-numeric features: {non_numeric}\")\n",
    "else:\n",
    "    print(\"All features are now numeric.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eda2268",
   "metadata": {},
   "source": [
    "### 3.2 Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56063263",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "dataset_scaled = dataset_encoded.copy()\n",
    "\n",
    "features_to_scale = [col for col in dataset_scaled.columns if col != 'loan_status']\n",
    "\n",
    "scaler_standard = StandardScaler()\n",
    "dataset_scaled_standard = dataset_scaled.copy()\n",
    "dataset_scaled_standard[features_to_scale] = scaler_standard.fit_transform(dataset_scaled[features_to_scale])\n",
    "\n",
    "scaler_minmax = MinMaxScaler()\n",
    "dataset_scaled_minmax = dataset_scaled.copy()\n",
    "dataset_scaled_minmax[features_to_scale] = scaler_minmax.fit_transform(dataset_scaled[features_to_scale])\n",
    "\n",
    "print(\"Summary statistics after standardization:\")\n",
    "display(dataset_scaled_standard.describe())\n",
    "print(\"\\nSummary statistics after normalization:\")\n",
    "display(dataset_scaled_minmax.describe())\n",
    "\n",
    "dataset_scaled = dataset_scaled_standard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e0f35b",
   "metadata": {},
   "source": [
    "### 3.3 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fb12a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "\n",
    "X = dataset_encoded.drop('loan_status', axis=1)\n",
    "y = dataset_encoded['loan_status']\n",
    "\n",
    "selector_f = SelectKBest(f_classif, k=8)  \n",
    "X_selected_f = selector_f.fit_transform(X, y)\n",
    "\n",
    "selected_features_f = X.columns[selector_f.get_support()]\n",
    "print(\"Top features selected by ANOVA F-test:\")\n",
    "display(selected_features_f)\n",
    "\n",
    "selector_mi = SelectKBest(mutual_info_classif, k=8) \n",
    "X_selected_mi = selector_mi.fit_transform(X, y)\n",
    "\n",
    "selected_features_mi = X.columns[selector_mi.get_support()]\n",
    "print(\"\\nTop features selected by Mutual Information:\")\n",
    "display(selected_features_mi)\n",
    "\n",
    "f_scores = selector_f.scores_\n",
    "mi_scores = selector_mi.scores_\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'F-Score': f_scores,\n",
    "    'MI-Score': mi_scores\n",
    "})\n",
    "feature_importance = feature_importance.sort_values(by='F-Score', ascending=False)\n",
    "display(feature_importance)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(x='F-Score', y='Feature', data=feature_importance.sort_values('F-Score', ascending=False))\n",
    "plt.title('Feature Importance (F-Score)')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.barplot(x='MI-Score', y='Feature', data=feature_importance.sort_values('MI-Score', ascending=False))\n",
    "plt.title('Feature Importance (Mutual Information)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ff02a9",
   "metadata": {},
   "source": [
    "## 4. Data Splitting and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34cd937",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_dataset, test_dataset = train_test_split(\n",
    "    dataset_encoded, \n",
    "    test_size=0.25,  \n",
    "    random_state=42, \n",
    "    stratify=dataset_encoded['loan_status']  \n",
    ")\n",
    "\n",
    "print(f\"Training dataset shape: {train_dataset.shape}\")\n",
    "print(f\"Testing dataset shape: {test_dataset.shape}\")\n",
    "\n",
    "original_percentage = (dataset_encoded['loan_status'].value_counts(normalize=True) * 100).loc[1]\n",
    "train_percentage = (train_dataset['loan_status'].value_counts(normalize=True) * 100).loc[1]\n",
    "test_percentage = (test_dataset['loan_status'].value_counts(normalize=True) * 100).loc[1]\n",
    "\n",
    "print(f\"\\nPercentage of defaults in original dataset: {original_percentage:.2f}%\")\n",
    "print(f\"Percentage of defaults in training dataset: {train_percentage:.2f}%\")\n",
    "print(f\"Percentage of defaults in testing dataset: {test_percentage:.2f}%\")\n",
    "\n",
    "X_train = train_dataset.drop(columns=['loan_status'])\n",
    "y_train = train_dataset['loan_status']\n",
    "X_test = test_dataset.drop(columns=['loan_status'])\n",
    "y_test = test_dataset['loan_status']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "train_dataset.to_csv('data/train.csv', index=False)\n",
    "test_dataset.to_csv('data/test.csv', index=False)\n",
    "print(\"\\nTraining and testing datasets saved to files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9301773",
   "metadata": {},
   "source": [
    "## 5. Model Implementation and Evaluation\n",
    "\n",
    "Após ter estabelecido o spliting do dataset em treino e teste, passamos para a parte de criar os modelos.\n",
    "\n",
    "### 5.1 Model Training and Evaluation Function\n",
    "Esta função corresponde ao processo comum entre qualquer um dos algoritmos de classificação escolhidos. Todos eles necessitam de ser treinados, testados e depois avaliados. Para o mesmo datasets de treino e teste, são testados diferentes parâmetros nos algoritmos de classificação. Os critérios utlizados para a sua classificação foram:\n",
    "- Accuracy:\n",
    "- Precision:\n",
    "- Recall: \n",
    "- F1-Score:\n",
    "- Training Time:\n",
    "- Testing Time: \n",
    "\n",
    "Após a obtenção destas métricas, para cada um dos modelos é apresentado um gráfico de confusão e um outro gráfico com a importância que esse modelo deu para cada uma das features disponíveis. Para cada modelo, pode haver ainda outros gráficos/informações que são relevantes para cada um dos modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d74da0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import time\n",
    "\n",
    "def train_and_evaluate_model(model, X_train, y_train, X_test, y_test, model_name, scaled=False):\n",
    "    \"\"\"\n",
    "    Train and evaluate a model with comprehensive metrics.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: The model to train\n",
    "    - X_train, y_train: Training data\n",
    "    - X_test, y_test: Testing data\n",
    "    - model_name: Name of the model for display\n",
    "    - scaled: Whether the data should be scaled\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary with model performance metrics\n",
    "    \"\"\"\n",
    "    if scaled:\n",
    "        X_train_use = X_train_scaled\n",
    "        X_test_use = X_test_scaled\n",
    "    else:\n",
    "        X_train_use = X_train\n",
    "        X_test_use = X_test\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model.fit(X_train_use, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    y_pred = model.predict(X_test_use)\n",
    "    test_time = time.time() - start_time\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\n{model_name} Model Evaluation:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(f\"Training Time: {train_time:.4f} seconds\")\n",
    "    print(f\"Testing Time: {test_time:.4f} seconds\")\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['No Default', 'Default'],\n",
    "                yticklabels=['No Default', 'Default'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'train_time': train_time,\n",
    "        'test_time': test_time,\n",
    "        'model': model\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdb975d",
   "metadata": {},
   "source": [
    "### 5.2 Decision Tree Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41c67ee",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a7cb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "dt_results = train_and_evaluate_model(dt_model, X_train, y_train, X_test, y_test, \"Decision Tree\")\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(\n",
    "    dt_model, \n",
    "    feature_names=X_train.columns, \n",
    "    class_names=['No Default', 'Default'],\n",
    "    filled=True, \n",
    "    rounded=True,\n",
    "    max_depth=3 \n",
    ")\n",
    "plt.title(\"Decision Tree Visualization (Limited to Depth 3)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': dt_model.feature_importances_\n",
    "})\n",
    "feature_importance = feature_importance.sort_values('Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance)\n",
    "plt.title('Feature Importance from Decision Tree')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e980164b",
   "metadata": {},
   "source": [
    "### 5.3 K-Nearest Neighbors Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27feb614",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "param_grid = {'n_neighbors': list(range(3, 21, 2))}\n",
    "grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_k = grid_search.best_params_['n_neighbors']\n",
    "print(f\"Best value of k: {best_k}\")\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=best_k)\n",
    "knn_results = train_and_evaluate_model(knn_model, X_train, y_train, X_test, y_test, \"K-Nearest Neighbors\", scaled=True)\n",
    "\n",
    "k_range = list(range(3, 21, 2))\n",
    "accuracy_scores = []\n",
    "\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    y_pred = knn.predict(X_test_scaled)\n",
    "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_range, accuracy_scores)\n",
    "plt.xlabel('Value of K')\n",
    "plt.ylabel('Testing Accuracy')\n",
    "plt.title('KNN Performance with Different K Values')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b29b63e",
   "metadata": {},
   "source": [
    "### 5.4 Support Vector Machine Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59127745",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "svm_results = train_and_evaluate_model(svm_model, X_train, y_train, X_test, y_test, \"Support Vector Machine\", scaled=True)\n",
    "\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "kernel_results = []\n",
    "\n",
    "for kernel in kernels:\n",
    "    print(f\"\\nTraining SVM with {kernel} kernel...\")\n",
    "    svm = SVC(kernel=kernel, random_state=42)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    svm.fit(X_train_scaled, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    y_pred = svm.predict(X_test_scaled)\n",
    "    test_time = time.time() - start_time\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    kernel_results.append({\n",
    "        'kernel': kernel,\n",
    "        'accuracy': accuracy,\n",
    "        'train_time': train_time,\n",
    "        'test_time': test_time\n",
    "    })\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Training Time: {train_time:.4f} seconds\")\n",
    "    print(f\"Testing Time: {test_time:.4f} seconds\")\n",
    "\n",
    "kernel_df = pd.DataFrame(kernel_results)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(x='kernel', y='accuracy', data=kernel_df)\n",
    "plt.title('SVM Accuracy by Kernel')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Kernel Type')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.barplot(x='kernel', y='train_time', data=kernel_df)\n",
    "plt.title('SVM Training Time by Kernel')\n",
    "plt.ylabel('Training Time (seconds)')\n",
    "plt.xlabel('Kernel Type')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f7e945",
   "metadata": {},
   "source": [
    "### 5.5 Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de1b51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "nn_model = MLPClassifier(random_state=42, max_iter=1000)\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'alpha': [0.0001, 0.001, 0.01]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(nn_model, param_grid, cv=3, scoring='accuracy')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best Neural Network parameters: {best_params}\")\n",
    "\n",
    "nn_model = MLPClassifier(random_state=42, max_iter=1000, **best_params)\n",
    "nn_results = train_and_evaluate_model(nn_model, X_train, y_train, X_test, y_test, \"Neural Network\", scaled=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(nn_model.loss_curve_)\n",
    "plt.title('Neural Network Learning Curve')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce80ddc",
   "metadata": {},
   "source": [
    "### 5.6 Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a6d5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf_results = train_and_evaluate_model(rf_model, X_train, y_train, X_test, y_test, \"Random Forest\")\n",
    "\n",
    "feature_importance_rf = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "})\n",
    "feature_importance_rf = feature_importance_rf.sort_values('Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance_rf)\n",
    "plt.title('Feature Importance from Random Forest')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467801ac",
   "metadata": {},
   "source": [
    "## 6. Model Comparison and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ff17aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_results = [dt_results, knn_results, svm_results, nn_results, rf_results]\n",
    "\n",
    "comparison_df = pd.DataFrame(models_results)\n",
    "\n",
    "ordered_columns = ['model_name', 'accuracy', 'precision', 'recall', 'f1', 'train_time', 'test_time']\n",
    "comparison_df = comparison_df[ordered_columns]\n",
    "\n",
    "print(\"Model Comparison:\")\n",
    "display(comparison_df)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.barplot(x='model_name', y='accuracy', data=comparison_df)\n",
    "plt.title('Model Accuracy Comparison')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylim(0.7, 1.0)  \n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "precision_recall_df = comparison_df.melt(\n",
    "    id_vars='model_name', \n",
    "    value_vars=['precision', 'recall'], \n",
    "    var_name='Metric', \n",
    "    value_name='Value'\n",
    ")\n",
    "sns.barplot(x='model_name', y='Value', hue='Metric', data=precision_recall_df)\n",
    "plt.title('Precision and Recall Comparison')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylim(0.7, 1.0) \n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.barplot(x='model_name', y='f1', data=comparison_df)\n",
    "plt.title('F1-Score Comparison')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylim(0.7, 1.0) \n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.barplot(x='model_name', y='train_time', data=comparison_df)\n",
    "plt.title('Training Time Comparison')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Time (seconds)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "best_accuracy = comparison_df.loc[comparison_df['accuracy'].idxmax()]\n",
    "best_f1 = comparison_df.loc[comparison_df['f1'].idxmax()]\n",
    "fastest_model = comparison_df.loc[comparison_df['train_time'].idxmin()]\n",
    "\n",
    "print(f\"Best model by accuracy: {best_accuracy['model_name']} with {best_accuracy['accuracy']:.4f}\")\n",
    "print(f\"Best model by F1-score: {best_f1['model_name']} with {best_f1['f1']:.4f}\")\n",
    "print(f\"Fastest model: {fastest_model['model_name']} with {fastest_model['train_time']:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be14640e",
   "metadata": {},
   "source": [
    "## 7. Cross-Validation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68129cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Define cv_results to store cross-validation scores for each model\n",
    "cv_results = {}\n",
    "for result in models_results:\n",
    "    model_name = result['model_name']\n",
    "    model = result['model']\n",
    "    scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "    cv_results[model_name] = {'scores': scores}\n",
    "\n",
    "# Extract model names from comparison_df\n",
    "model_names = comparison_df['model_name'].tolist()\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "for i, name in enumerate(model_names):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.boxplot(cv_results[name]['scores'])\n",
    "    plt.title(f'{name} CV Scores')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba2ff84",
   "metadata": {},
   "source": [
    "## 8. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b792716",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance.head(10))\n",
    "plt.title('Top 10 Features (Decision Tree)')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance_rf.head(10))\n",
    "plt.title('Top 10 Features (Random Forest)')\n",
    "plt.tight_layout()\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "result = permutation_importance(knn_model, X_test_scaled, y_test, n_repeats=10, random_state=42)\n",
    "perm_importance = pd.DataFrame({\n",
    "    'Feature': X_test.columns,\n",
    "    'Importance': result.importances_mean\n",
    "})\n",
    "perm_importance = perm_importance.sort_values('Importance', ascending=False)\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.barplot(x='Importance', y='Feature', data=perm_importance.head(10))\n",
    "plt.title('Top 10 Features (KNN - Permutation Importance)')\n",
    "plt.tight_layout()\n",
    "\n",
    "result_nn = permutation_importance(nn_model, X_test_scaled, y_test, n_repeats=10, random_state=42)\n",
    "perm_importance_nn = pd.DataFrame({\n",
    "    'Feature': X_test.columns,\n",
    "    'Importance': result_nn.importances_mean\n",
    "})\n",
    "perm_importance_nn = perm_importance_nn.sort_values('Importance', ascending=False)\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.barplot(x='Importance', y='Feature', data=perm_importance_nn.head(10))\n",
    "plt.title('Top 10 Features (Neural Network - Permutation Importance)')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a492fe76",
   "metadata": {},
   "source": [
    "## 9. Hyperparameter Tuning\n",
    "\n",
    "### 9.1 Random Forest Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad584ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 500),\n",
    "    'max_depth': [None] + list(range(5, 30, 5)),\n",
    "    'min_samples_split': randint(2, 20),\n",
    "    'min_samples_leaf': randint(1, 10)\n",
    "}\n",
    "\n",
    "rf_random = RandomizedSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for Random Forest:\")\n",
    "print(rf_random.best_params_)\n",
    "print(f\"Best cross-validation score: {rf_random.best_score_:.4f}\")\n",
    "\n",
    "best_rf_model = RandomForestClassifier(random_state=42, **rf_random.best_params_)\n",
    "best_rf_results = train_and_evaluate_model(best_rf_model, X_train, y_train, X_test, y_test, \"Tuned Random Forest\")\n",
    "\n",
    "print(\"\\nComparison of Random Forest Models:\")\n",
    "comparison = pd.DataFrame([\n",
    "    {\n",
    "        'Model': 'Original Random Forest',\n",
    "        'Accuracy': rf_results['accuracy'],\n",
    "        'F1-Score': rf_results['f1']\n",
    "    },\n",
    "    {\n",
    "        'Model': 'Tuned Random Forest',\n",
    "        'Accuracy': best_rf_results['accuracy'],\n",
    "        'F1-Score': best_rf_results['f1']\n",
    "    }\n",
    "])\n",
    "display(comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f0d3de",
   "metadata": {},
   "source": [
    "### 9.2 Decision Tree Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbcb468",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_dt = {\n",
    "    'max_depth': [None] + list(range(5, 30, 5)),\n",
    "    'min_samples_split': range(2, 11),\n",
    "    'min_samples_leaf': range(1, 11),\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "dt_grid = GridSearchCV(\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    param_grid=param_grid_dt,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "dt_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for Decision Tree:\")\n",
    "print(dt_grid.best_params_)\n",
    "print(f\"Best cross-validation score: {dt_grid.best_score_:.4f}\")\n",
    "\n",
    "best_dt_model = DecisionTreeClassifier(random_state=42, **dt_grid.best_params_)\n",
    "best_dt_results = train_and_evaluate_model(best_dt_model, X_train, y_train, X_test, y_test, \"Tuned Decision Tree\")\n",
    "\n",
    "print(\"\\nComparison of Decision Tree Models:\")\n",
    "comparison_dt = pd.DataFrame([\n",
    "    {\n",
    "        'Model': 'Original Decision Tree',\n",
    "        'Accuracy': dt_results['accuracy'],\n",
    "        'F1-Score': dt_results['f1']\n",
    "    },\n",
    "    {\n",
    "        'Model': 'Tuned Decision Tree',\n",
    "        'Accuracy': best_dt_results['accuracy'],\n",
    "        'F1-Score': best_dt_results['f1']\n",
    "    }\n",
    "])\n",
    "display(comparison_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b679df3d",
   "metadata": {},
   "source": [
    "## 10. Model Interpretability\n",
    "\n",
    "### 10.1 SHAP Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffb4696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Initialize the SHAP explainer\n",
    "explainer = shap.TreeExplainer(best_rf_model)\n",
    "\n",
    "# Get SHAP values\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Check if the model is binary or multi-class\n",
    "if isinstance(shap_values, list):\n",
    "    # For multi-class models, select the SHAP values for the positive class (e.g., class 1)\n",
    "    shap_values_to_plot = shap_values[1]  # Adjust the index if needed\n",
    "else:\n",
    "    # For binary models, shap_values is a single array\n",
    "    shap_values_to_plot = shap_values\n",
    "\n",
    "# Plot the SHAP summary\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(shap_values_to_plot, X_test, feature_names=X_test.columns)\n",
    "plt.title('SHAP Feature Importance for Loan Default Prediction')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot SHAP dependence plots for the top features\n",
    "top_features = feature_importance_rf.head(3)['Feature'].values\n",
    "for feature in top_features:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    shap.dependence_plot(feature, shap_values_to_plot, X_test, feature_names=X_test.columns)\n",
    "    plt.title(f'SHAP Dependence Plot for {feature}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acddfc77",
   "metadata": {},
   "source": [
    "### 10.2 Partial Dependence Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d802438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "top_features = feature_importance_rf.head(3)['Feature'].values\n",
    "display = PartialDependenceDisplay.from_estimator(best_rf_model, X_test, features=top_features, ax=ax)\n",
    "plt.suptitle('Partial Dependence Plots for Top Features (Random Forest)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c4dbf4",
   "metadata": {},
   "source": [
    "## 11. Final Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8ffa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_models = [\n",
    "    dt_results,\n",
    "    best_dt_results,\n",
    "    knn_results,\n",
    "    svm_results,\n",
    "    nn_results,\n",
    "    rf_results,\n",
    "    best_rf_results\n",
    "]\n",
    "\n",
    "final_comparison = pd.DataFrame(final_models)[['model_name', 'accuracy', 'precision', 'recall', 'f1', 'train_time', 'test_time']]\n",
    "\n",
    "final_comparison = final_comparison.sort_values('f1', ascending=False)\n",
    "\n",
    "print(\"Final Model Comparison (Sorted by F1-Score):\")\n",
    "display(final_comparison)\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.barplot(x='model_name', y='accuracy', data=final_comparison)\n",
    "plt.title('Model Accuracy Comparison')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylim(0.7, 1.0)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.barplot(x='model_name', y='f1', data=final_comparison)\n",
    "plt.title('Model F1-Score Comparison')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylim(0.7, 1.0)\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "precision_recall_df = final_comparison.melt(\n",
    "    id_vars='model_name', \n",
    "    value_vars=['precision', 'recall'], \n",
    "    var_name='Metric', \n",
    "    value_name='Value'\n",
    ")\n",
    "sns.barplot(x='model_name', y='Value', hue='Metric', data=precision_recall_df)\n",
    "plt.title('Precision and Recall Comparison')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylim(0.7, 1.0)\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.barplot(x='model_name', y='train_time', data=final_comparison)\n",
    "plt.title('Training Time Comparison')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Time (seconds)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07876a36",
   "metadata": {},
   "source": [
    "## 12. Conclusion and Discussion\n",
    "\n",
    "Based on our comprehensive analysis of the loan prediction dataset, we can draw several important conclusions:\n",
    "\n",
    "1. **Best Performing Model**: The tuned Random Forest model achieved the highest overall performance with excellent accuracy and F1-score. The model successfully balances precision and recall, making it suitable for loan default prediction where both false positives and false negatives have significant consequences.\n",
    "\n",
    "2. **Feature Importance**: Through multiple analysis methods (Decision Tree, Random Forest, SHAP values), we found that the most important features for predicting loan defaults were:\n",
    "   - `loan_percent_income`: The ratio of loan amount to income is a strong predictor\n",
    "   - `loan_grade`: The assigned loan grade by the financial institution provides valuable information\n",
    "   - `person_income`: The applicant's income level plays a crucial role\n",
    "   - `loan_int_rate`: The interest rate assigned to the loan is an important indicator\n",
    "\n",
    "3. **Model Selection Considerations**:\n",
    "   - **Random Forest**: Best overall performer with excellent accuracy and F1-score, but with moderate training time\n",
    "   - **Decision Tree**: Simpler model with good interpretability and fast training time, but slightly lower accuracy\n",
    "   - **KNN**: Good accuracy when properly tuned, but slower prediction time with larger datasets\n",
    "   - **SVM**: Strong performance with linear kernel but significantly higher training time with large datasets\n",
    "   - **Neural Network**: Good performance but longer training time and less interpretability\n",
    "\n",
    "4. **Trade-offs**:\n",
    "   - There's a clear trade-off between model complexity/accuracy and training/inference time\n",
    "   - More complex models (Random Forest, Neural Network) generally performed better but required more computational resources\n",
    "   - Simpler models (Decision Tree, KNN) offer reasonable performance with faster training\n",
    "\n",
    "5. **Practical Implementation**: For a production environment, the tuned Random Forest model would be recommended due to its superior performance, reasonable training time, and good interpretability through feature importance and SHAP values.\n",
    "\n",
    "6. **Future Work**: To further improve the model, we could:\n",
    "   - Collect more data to better represent edge cases\n",
    "   - Engineer additional features that capture financial behavior patterns\n",
    "   - Explore ensemble methods that combine multiple models\n",
    "   - Address class imbalance through advanced techniques like SMOTE or adaptive sampling\n",
    "\n",
    "The loan default prediction model developed in this project demonstrates the effectiveness of machine learning approaches for risk assessment in financial institutions. By accurately identifying potential defaults, institutions can make more informed lending decisions, reduce financial losses, and potentially offer better terms to low-risk applicants.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cc6257",
   "metadata": {},
   "source": [
    "## 13. References\n",
    "\n",
    "1. Scikit-learn: Machine Learning in Python, Pedregosa et al., JMLR 12, pp. 2825-2830, 2011.\n",
    "2. \"Random Forests\", Leo Breiman, Machine Learning, 45(1), 5-32, 2001.\n",
    "3. \"A Comparative Study of Classification Algorithms for Credit Risk Prediction\", Chaudhuri & De, 2011.\n",
    "4. Lundberg, S.M., Lee, S.I. (2017). \"A Unified Approach to Interpreting Model Predictions.\" Advances in Neural Information Processing Systems 30.\n",
    "5. Kaggle Credit Risk Dataset: https://www.kaggle.com/datasets/laotse/credit-risk-dataset\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia_project_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
