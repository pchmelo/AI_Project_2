{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72484eb2",
   "metadata": {},
   "source": [
    "# Loan Prediction\n",
    "\n",
    "### Developed by:\n",
    "\n",
    "1. Tiago Pinheiro - 202205295\n",
    "2. Tiago Rocha    - 202005428\n",
    "3. Vasco Melo     - 202207564"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36550142",
   "metadata": {},
   "source": [
    "### The problem\n",
    "\n",
    "This project's goal is to predict whether an applicant is approved for a loan.\n",
    "\n",
    "### The dataset \n",
    "\n",
    "To acomplish our goal we used the dataset for Loan Approval Prediction from Kaggle. It contains about 32600 entries, each with 12 attributes, but only 8 of those are numeric-valued. The not numeric ones are as follows:\n",
    "- person_age:\n",
    "    - Age of the loan applicant in years. \n",
    "    - If the applicant's age is of one extreme or the other, being too old or too young, his loan will most likely have higher chances of being refused.\n",
    "- person_income:\n",
    "    - Annual income of the applicant in currency units. \n",
    "    - A higher income strongly correlates to a loan being approved, as the applicant with have higher repayment capability and capacity.\n",
    "- person_home_ownership:\n",
    "    - Housing status of applicant, categorized with four different options, those being MORTGAGE, RENT, OWN and OTHER. \n",
    "    - Home ownership can directly correlate to the financial stability of the applicant while also providing potential collateral, thus facilitating a loan's approval.\n",
    "- person_emp_length:\n",
    "    - Number of years the applicant has been employed at their current job. \n",
    "    - As with housing status, their employment length can correspond to the applicant's income and financial stability, as the longer it is the more stable their financial status is more likely to be.\n",
    "- loan_intent:\n",
    "    - The stated purpose for the loan, categorized with six different options, those being VENTURE, EDUCATION, DEBTCONSOLIDATION, HOMEIMPROVEMENT, MEDICAL and PERSONAL. \n",
    "    - Loan purpose affects risk assessment, as for example education or home improvement motives will likely carry out to a higher earning capacity or asset value, while others like venture or personal are riskier and more prone failure in repaying.\n",
    "- loan_grade: \n",
    "    - The credit quality grade assigned to the loan, ranging from A to G, best to worst.\n",
    "    - Loan grade is used as approval likelihood, representing the lender's internal credit risk assessment. The higher the grade, the lower interest rates and higher approval rates one gets, and vice versa.\n",
    "- loan_amnt:\n",
    "    - The requested loan amount.\n",
    "    - Larger loan amounts obviously represent higher absolute risk for lenders. As a norm, the higher the loan amount the lower the approval threshold, requiring stronger compensating factors like higher income and better credit history.\n",
    "- loan_int_rate:\n",
    "    - The annual interest rate charged on the loan.\n",
    "    - Interest rates reflect risk assessment, as higher rates likely indicate higher perceived risk.\n",
    "- loan_status:\n",
    "    - The target variable, 1 being approved and 0 not approved.\n",
    "    - This is the outcome variable the model will predict.\n",
    "- loan_percent_income:\n",
    "    - The percentage of applicant's income represented by the loan payment.\n",
    "    - This is a critical debt-to-income component, as higher percentages represent greater financial strains. Values of 50% and above face significantly higher rejection.\n",
    "- cb_person_default_on_file: \n",
    "    - Credit bureau record of whether the person has defaulted before, 'Y' for yes and 'N' for no.\n",
    "    - If an applicant has previous defaults, it will dramatically reduce approval chances, as they are strong negative indicators of repayment capability.\n",
    "- cb_person_cred_hist_length:\n",
    "    - Length of the person's credit history in years.\n",
    "    - Longer credit histories allow better risk assessment and generally improve approval chances.\n",
    "    \n",
    "### The solution\n",
    "\n",
    "To solve this problem, we used a supervised learning model trained on Kaggleâ€™s dataset. The modelâ€™s performance was measured using the accuracy metric, which represents the percentage of correct predictions made by the model out of all predictions. In other words, it shows how often the model correctly classified whether a loan was paid or not.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3d4296",
   "metadata": {},
   "source": [
    "_____________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18800d8f",
   "metadata": {},
   "source": [
    "### Pre analysis\n",
    "To start we imported the pandas library, and checked the dataset to get a better understanding of the data and to find possible outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903c5108",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "dataset = pd.read_csv('data/credit_risk_dataset.csv')\n",
    "\n",
    "print(dataset.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469894df",
   "metadata": {},
   "source": [
    "##### Data Cleaning\n",
    "Person age\n",
    "- There are outliers of people that are 120 years old plus.\n",
    "\n",
    "Person employment \n",
    "- Someone can't be working for longer than they have been alive.\n",
    "\n",
    "Note: a total of 6 rows were removed in this part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b0045a",
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_age_entries = dataset[dataset['person_age'] > 120]\n",
    "print(\"Entries with person_age > 120:\")\n",
    "print(removed_age_entries)\n",
    "\n",
    "# Find entries where person_emp_length > person_age\n",
    "removed_emp_length_entries = dataset[dataset['person_emp_length'] > dataset['person_age']]\n",
    "print(\"\\nEntries with person_emp_length > person_age:\")\n",
    "print(removed_emp_length_entries)\n",
    "\n",
    "# Combine all removed entries for reference\n",
    "all_removed_entries = pd.concat([removed_age_entries, removed_emp_length_entries]).drop_duplicates()\n",
    "print(\"\\nAll entries to be removed:\")\n",
    "print(all_removed_entries)\n",
    "\n",
    "# Remove invalid entries from the dataset\n",
    "dataset = dataset[dataset['person_age'] <= 120]\n",
    "dataset = dataset[dataset['person_emp_length'] <= dataset['person_age']]\n",
    "\n",
    "# Display the updated dataset\n",
    "print(\"\\nDataset after removing invalid entries:\")\n",
    "print(dataset.describe())\n",
    "\n",
    "# Display total rows removed\n",
    "print(f\"\\nTotal rows removed: {len(all_removed_entries)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96f015d",
   "metadata": {},
   "source": [
    "To complete the cleaning  we removed any incomplete rows\n",
    "\n",
    "Note: a total of 3943 rows were removed in this part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b8518e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find incomplete data (missing values)\n",
    "print(\"Incomplete data (missing values) in the dataset:\")\n",
    "\n",
    "# Check for missing values in each column\n",
    "missing_data = dataset.isnull().sum()\n",
    "\n",
    "# Display columns with missing values\n",
    "missing_data = missing_data[missing_data > 0]\n",
    "if not missing_data.empty:\n",
    "    print(missing_data)\n",
    "else:\n",
    "    print(\"No missing values found in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b561594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_before = len(dataset)\n",
    "\n",
    "# Remove rows with missing values in the dataset\n",
    "dataset = dataset.dropna()\n",
    "\n",
    "# Print how many rows were removed\n",
    "rows_after = len(dataset)\n",
    "rows_removed = rows_before - rows_after\n",
    "print(f\"\\nTotal rows removed due to missing values: {rows_removed}\")\n",
    "\n",
    "\n",
    "# Verify that there are no more missing values\n",
    "print(\"Dataset after removing rows with missing values:\")\n",
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f6c0c3",
   "metadata": {},
   "source": [
    "##### Data Encoding\n",
    "After cleaning the dataset, we needed to convert categorical (non-numeric) columns into numerical format, as most machine learning algorithms require numerical input. This process, known as encoding, allows the model to interpret qualitative information such as loan intent, employment type, or home ownership. Depending on whether the categories had a meaningful order or not, we applied appropriate encoding techniques to preserve the underlying structure of the data while making it usable for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdc8e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map to convert 'person_home_ownership' to numeric values\n",
    "home_ownership_map = {\n",
    "    'MORTGAGE': 0,\n",
    "    'RENT': 1,\n",
    "    'OWN': 2,\n",
    "    'OTHER': 3\n",
    "}\n",
    "\n",
    "# Apply the mapping to the 'person_home_ownership' column\n",
    "dataset['person_home_ownership'] = dataset['person_home_ownership'].map(home_ownership_map)\n",
    "\n",
    "# Verify the transformation\n",
    "print(\"Transformed 'person_home_ownership' column:\")\n",
    "print(dataset['person_home_ownership'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653505b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map to convert 'loan_intent' to numeric values\n",
    "loan_intent_map = {\n",
    "    'VENTURE': 0,\n",
    "    'EDUCATION': 1,\n",
    "    'DEBTCONSOLIDATION': 2,\n",
    "    'HOMEIMPROVEMENT': 3,\n",
    "    'MEDICAL': 4,\n",
    "    'PERSONAL': 5\n",
    "}\n",
    "\n",
    "# Apply the mapping to the 'loan_intent' column\n",
    "dataset['loan_intent'] = dataset['loan_intent'].map(loan_intent_map)\n",
    "\n",
    "# Verify the transformation\n",
    "print(\"Transformed 'loan_intent' column:\")\n",
    "print(dataset['loan_intent'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326e7e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map to convert 'loan_grade' to numeric values\n",
    "loan_grade_map = {\n",
    "    'A': 0,\n",
    "    'B': 1,\n",
    "    'C': 2,\n",
    "    'D': 3,\n",
    "    'E': 4,\n",
    "    'F': 5,\n",
    "    'G': 6\n",
    "}\n",
    "\n",
    "# Apply the mapping to the 'loan_grade' column\n",
    "dataset['loan_grade'] = dataset['loan_grade'].map(loan_grade_map)\n",
    "\n",
    "# Verify the transformation\n",
    "print(\"Transformed 'loan_grade' column:\")\n",
    "print(dataset['loan_grade'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13802738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map to convert 'cb_person_default_on_file' to numeric values\n",
    "cb_person_default_map = {\n",
    "    'Y': 1,\n",
    "    'N': 0\n",
    "}\n",
    "\n",
    "# Apply the mapping to the 'cb_person_default_on_file' column\n",
    "dataset['cb_person_default_on_file'] = dataset['cb_person_default_on_file'].map(cb_person_default_map)\n",
    "\n",
    "# Verify the transformation\n",
    "print(\"Transformed 'cb_person_default_on_file' column:\")\n",
    "print(dataset['cb_person_default_on_file'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89979b03",
   "metadata": {},
   "source": [
    "##### Data Analysis\n",
    "\n",
    "After completing the data preprocessing steps, we conducted an exploratory data analysis to understand the relationships between various features and the loan approval status. This analysis aimed to identify patterns and correlations that could inform our predictive modeling.\n",
    "\n",
    "Key Observations:\n",
    "\n",
    "loan_int_rate: higher interest rates are more commonly associated with approved loans. Lenders may be more inclined to approve loans with higher interest rates as they offer greater returns, potentially offsetting the risk associated with the borrower.\n",
    "\n",
    "loan_percent_income: loans constituting a higher percentage of the borrower's income tend to have higher approval rates. This could indicate that lenders are willing to approve loans that represent a significant portion of the borrower's income, possibly due to confidence in the borrower's repayment capacity or other compensating factors.\n",
    "\n",
    "##### Feature Importance Analysis:\n",
    "To quantitatively assess the impact of each feature on loan approval, we employed a Decision Tree Classifier to evaluate feature importance. The results indicated that:\n",
    "\n",
    "High Importance Features: loan_int_rate, loan_percent_income, and person_income emerged as the most influential predictors.\n",
    "\n",
    "Low Importance Features: person_home_ownership and loan_grade showed minimal impact on the model's predictive power.\n",
    "\n",
    "These findings align with the observations from our exploratory analysis, reinforcing the significance of financial metrics over demographic factors in loan approval decisions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcdc0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_plot = [col for col in dataset.columns if col != 'id']\n",
    "\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sb.pairplot(dataset[columns_to_plot].dropna(), hue='loan_status')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54d965b",
   "metadata": {},
   "source": [
    "The scatter plot of loan_percent_income and loan_int_rate is the most effective for explaining loan approval decisions. This plot reveals a clear separation between approved and denied applications, forming visible clusters that reflect different approval patterns. It visually captures the combined influence of how much of a borrower's income is allocated to the loan and the interest rate they are offered, making it an ideal representation for identifying trends and building intuitive decision boundaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfa938d",
   "metadata": {},
   "source": [
    "______________________________________________________________________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ae8afb",
   "metadata": {},
   "source": [
    "To further explore the relationship between each feature and the loan status, we used violin plots. These plots display the distribution and density of values for each feature, grouped by whether the loan was paid or not paid. This visualization helps highlight differences in how features like income, interest rate, or credit score vary depending on the repayment outcome. By organizing the plots in a grid, we can efficiently compare these distributions across multiple variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaf9b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "columns_to_plot = [col for col in dataset.columns if col != 'loan_status']\n",
    "\n",
    "num_columns = len(columns_to_plot)\n",
    "rows = (num_columns + 1) // 2  \n",
    "\n",
    "for column_index, column in enumerate(columns_to_plot):\n",
    "    plt.subplot(rows, 2, column_index + 1) \n",
    "    sb.violinplot(x='loan_status', y=column, data=dataset)\n",
    "\n",
    "plt.tight_layout()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d8339d",
   "metadata": {},
   "source": [
    "#### Some conclusions from the graphs\n",
    "\n",
    "ðŸ”¹ person_age: \n",
    "Older individuals are less likely to have their loan approved, as lenders might consider life expectancy and financial independence when assessing the likelihood of full repayment over the loan term.\n",
    "\n",
    "ðŸ”¹ person_income: \n",
    "Applicants with higher incomes are more likely to be approved because they demonstrate a stronger ability to repay the loan without financial strain.\n",
    "\n",
    "ðŸ”¹ person_home_ownership: \n",
    "Owning a home can increase approval chances, as it indicates financial stability and may provide collateral, reducing the lender's risk.\n",
    "\n",
    "ðŸ”¹ person_emp_length: \n",
    "Longer employment history is typically viewed positively, as it suggests job stability and a consistent income source, which are important for loan repayment.\n",
    "\n",
    "ðŸ”¹ loan_intent: \n",
    "The purpose of the loan can influence approval, as lenders may consider some intents (like medical or personal expenses) riskier than others (like home improvement or education).\n",
    "\n",
    "ðŸ”¹ loan_grade: \n",
    "Loan grade reflects the applicantâ€™s creditworthiness; lower grades are associated with higher risk and therefore a greater likelihood of rejection.\n",
    "\n",
    "ðŸ”¹ loan_amnt: \n",
    "Larger loan amounts may reduce the chances of approval, since they represent a greater financial risk for the lender if the borrower defaults.\n",
    "\n",
    "ðŸ”¹ loan_int_rate: \n",
    "Higher interest rates may increase the likelihood of loan approval, as lenders are more willing to take on higher-risk borrowers if they are compensated with greater returns.\n",
    "\n",
    "ðŸ”¹ loan_percent_income: \n",
    "Higher loan-to-income ratios are associated with higher approval rates, possibly indicating that lenders are more flexible when the borrower is willing to commit a larger portion of their income to repayment.\n",
    "\n",
    "ðŸ”¹ cb_person_default_on_file: \n",
    "Applicants with a history of default are much less likely to be approved, as past defaults are strong indicators of future risk and potential non-payment.\n",
    "\n",
    "ðŸ”¹ cb_person_cred_hist_length: \n",
    "A longer credit history gives lenders more information to evaluate credit behavior, which can increase the chances of approval due to a more established financial track record."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b140628",
   "metadata": {},
   "source": [
    "##### Data Splitting\n",
    "We split the dataset into training and testing sets using stratified sampling to ensure the proportion of approved and denied loans remained consistent across both sets. This helps maintain balance in the target variable and avoids bias during model training and evaluation. In real-world applications, splitting the dataset in this way is not a problem, because models are typically deployed to make predictions on data the model hasn't seen before â€” similar to our test set. Since the test data simulates future or unseen cases, keeping it separate ensures we can fairly evaluate the modelâ€™s generalization ability. Furthermore, stratified sampling avoids distortions in class distribution, which could otherwise lead to misleading performance metrics or poorly trained models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fcbcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets with the same distribution of loan_status\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Perform stratified sampling based on 'loan_status'\n",
    "train_dataset, test_dataset = train_test_split(\n",
    "    dataset, \n",
    "    test_size=0.25,  # 25% for testing\n",
    "    random_state=1,  # For reproducibility\n",
    "    stratify=dataset['loan_status']  # Maintain the same distribution of 'loan_status'\n",
    ")\n",
    "\n",
    "original_percentage = (dataset['loan_status'].value_counts(normalize=True) * 100).loc[1]\n",
    "print(\"Original dataset distribution:\")\n",
    "print(f\"Percentage of 1 in original dataset: {original_percentage:.2f}%\")\n",
    "\n",
    "# Print the percentage of 1 in the 'loan_status' column for the training dataset\n",
    "train_percentage = (train_dataset['loan_status'].value_counts(normalize=True) * 100).loc[1]\n",
    "print(f\"Percentage of 1 in training dataset: {train_percentage:.2f}%\")\n",
    "\n",
    "# Print the percentage of 1 in the 'loan_status' column for the testing dataset\n",
    "test_percentage = (test_dataset['loan_status'].value_counts(normalize=True) * 100).loc[1]\n",
    "print(f\"Percentage of 1 in testing dataset: {test_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af6aef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the training and testing datasets to CSV files\n",
    "train_dataset.to_csv('data/train.csv', index=False)\n",
    "test_dataset.to_csv('data/test.csv', index=False)\n",
    "\n",
    "print(\"Training dataset saved as 'train.csv'.\")\n",
    "print(\"Testing dataset saved as 'test.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14b5e1c",
   "metadata": {},
   "source": [
    "##### Model Training and Evaluation\n",
    "We trained a Decision Tree classifier to predict whether a loan will be paid or not, using the cleaned and encoded dataset. The model was trained on the training set and evaluated on the test set, achieving an accuracy of 91%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd26d8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Decision Tree model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Separate features (X) and target (y) for training and testing datasets\n",
    "X_train = train_dataset.drop(columns=['loan_status'])\n",
    "y_train = train_dataset['loan_status']\n",
    "X_test = test_dataset.drop(columns=['loan_status'])\n",
    "y_test = test_dataset['loan_status']\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "model = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate and display the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of the Decision Tree model: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84019c2b",
   "metadata": {},
   "source": [
    "To assess the stability of the Decision Tree model, we ran it 1000 times using different train-test splits while preserving the class distribution. We recorded the accuracy for each run and visualized the distribution with a histogram, allowing us to observe the consistency and variability in model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7147e349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Decision Tree model 1000 times with different splits and display a histogram of accuracies\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Store accuracies for each run\n",
    "accuracies = []\n",
    "\n",
    "# Run the model 1000 times\n",
    "for i in range(1000):\n",
    "    # Split the dataset into training and testing sets with stratified sampling\n",
    "    train_dataset, test_dataset = train_test_split(\n",
    "        dataset,\n",
    "        test_size=0.25,  # 25% for testing\n",
    "        random_state=i,  # Change random state for each iteration\n",
    "        stratify=dataset['loan_status']  # Maintain the same distribution of 'loan_status'\n",
    "    )\n",
    "    \n",
    "    # Separate features (X) and target (y) for training and testing datasets\n",
    "    X_train = train_dataset.drop(columns=['loan_status'])\n",
    "    y_train = train_dataset['loan_status']\n",
    "    X_test = test_dataset.drop(columns=['loan_status'])\n",
    "    y_test = test_dataset['loan_status']\n",
    "    \n",
    "    # Initialize the Decision Tree Classifier\n",
    "    model = DecisionTreeClassifier(random_state=i)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test dataset\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate and store the accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Calculate and display the average accuracy over 1000 runs\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f\"Average accuracy over 1000 runs: {average_accuracy:.2f}\")\n",
    "\n",
    "# Plot a histogram of the accuracies\n",
    "plt.hist(accuracies, bins=20, edgecolor='black')\n",
    "plt.title('Histogram of Model Accuracies')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935b0e14",
   "metadata": {},
   "source": [
    "##### Data Preparation\n",
    "To prepare the data for analysis, we selected a subset of relevant features from the dataset, including demographic, financial, and loan-related variables. These features were extracted into a matrix of inputs, while the loan status was stored separately as the target variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd5bf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparaÃ§Ã£o dos dados para anÃ¡lise\n",
    "credit_risk_dataset = pd.read_csv('data/credit_risk_dataset.csv')\n",
    "all_inputs = credit_risk_dataset[\n",
    "    [\n",
    "        'person_age',\n",
    "        'person_income',\n",
    "        'person_home_ownership',\n",
    "        'person_emp_length',\n",
    "        'loan_intent',\n",
    "        'loan_grade',\n",
    "        'loan_amnt',\n",
    "        'loan_int_rate',\n",
    "        'loan_percent_income',\n",
    "        'cb_person_cred_hist_length'\n",
    "    ]\n",
    "].values\n",
    "\n",
    "loan_status = credit_risk_dataset['loan_status'].values\n",
    "all_inputs[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
